<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Personal Research Assistant with Gen AI</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background-color: #f8f9fa;
      color: #2c2c2c;
      max-width: 800px;
      margin: auto;
      padding: 30px 20px;
    }

    header {
      text-align: center;
      padding-bottom: 20px;
    }

    h1 {
      color: #1a1a1a;
      font-size: 2.4em;
      margin-bottom: 10px;
    }

    h2 {
      color: #333;
      margin-top: 40px;
      border-bottom: 2px solid #ccc;
      padding-bottom: 5px;
    }

    ul {
      padding-left: 20px;
    }

    pre {
      background-color: #1e1e1e;
      color: #eaeaea;
      padding: 15px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.95em;
    }

    code {
      font-family: 'Courier New', Courier, monospace;
    }

    img {
      width: 100%;
      border: 1px solid #ddd;
      border-radius: 6px;
      margin: 20px 0;
    }

    footer {
      margin-top: 60px;
      text-align: center;
      color: #777;
      font-size: 0.9em;
    }

    a {
      color: #0077cc;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .tagline {
      font-size: 1.2em;
      color: #555;
      font-style: italic;
    }

  </style>
</head>
<body>

  <header>
    <h1>ğŸ“š Building a Personal Research Assistant with Gen AI</h1>
    <p class="tagline">Turn long documents into smart, conversational answers</p>
  </header>

  <p>
    Long academic papers, research reports, or technical documentation can be overwhelming. My capstone project tackles this head-on by building a <strong>"Personal Research Assistant"</strong> using Googleâ€™s Generative AI. The tool ingests PDFs, chunks and embeds them, and then uses summarization and Retrieval-Augmented Generation (RAG) to answer user questions â€” all powered by Gemini and VertexAI tools.
  </p>

  <h2>ğŸ” The Use Case</h2>
  <p>
    Researchers, students, and analysts often need to extract key information from long documents quickly. This assistant allows users to upload a document and interact with it conversationally â€” asking for summaries or querying specific information grounded in the original content.
  </p>

  <h2>ğŸ› ï¸ Core Capabilities</h2>
  <ul>
    <li>ğŸ’¡ Summarization with Gemini 1.5 Flash</li>
    <li>ğŸ“ Document Chunking & Embedding with LangChain + VertexAI</li>
    <li>ğŸ” Retrieval-Augmented Generation using FAISS Vector Store</li>
  </ul>

  <h2>ğŸ§ª Implementation</h2>

  <p><strong>Step 1: Load and chunk the PDF</strong></p>
  <img src="img/Screenshot (248).png" alt="Loading the PDF" />
  <img src="img/Screenshot (249).png" alt="Chunking code snippet" />


  <p><strong>Step 2: Summarize with Gemini</strong></p>
  <pre><code>
model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")
response = model.generate_content("Summarize the following:\n" + text_chunk)
print(response.text)
  </code></pre>
  <img src="img/Screenshot (250).png" alt="Summarization result" />

  <p><strong>Step 3: Create embeddings & vector store</strong></p>
  <img src="img/Screenshot (251).png" alt="FAISS creation" />
  <img src="img/Screenshot (252).png" alt="FAISS creation" />


  <p><strong>Step 4: Ask questions using RAG</strong></p>
  <img src="img/Screenshot (253).png" alt="RAG query and response" />
  <img src="img/Screenshot (254).png" alt="RAG query and response" />
  <img src="img/Screenshot (255).png" alt="RAG query and response" />



  <h2>âš ï¸ Limitations & Learnings</h2>
  <ul>
    <li>ğŸ” API key management requires care â€” always store in secrets.</li>
    <li>ğŸ“ Token limits mean large docs must be chunked thoughtfully.</li>
    <li>ğŸ’³ Some VertexAI features need project setup + billing enabled.</li>
  </ul>

  <h2>ğŸš€ Future Possibilities</h2>
  <p>
    The assistant currently works on PDFs, but future versions could ingest websites, YouTube transcripts, or even live Zoom calls. With Geminiâ€™s increasing context windows and vision support, the tool could evolve into a fully-fledged AI research co-pilot.
  </p>

  <h2>ğŸ’» Try It or Fork It</h2>
  <p>
    You can view the full code and notebook on <a href="https://www.kaggle.com/code/trevorokinda17/personal-research-assistant-for-long-papers-pdfs" target="_blank">Kaggle</a>, or deploy your own research assistant via <a href="https://vercel.com">Vercel</a>. Built entirely with Google tools, it shows how GenAI can solve real problems in productivity and research.
  </p>

  <footer>
    âœï¸ Written by <strong>Trevor Okinda</strong><br>
    Capstone Project for Gen AI Intensive (Google x Kaggle)
  </footer>

</body>
</html>
